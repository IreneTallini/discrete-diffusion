defaults:
  - graph_generator: balanced_tree
  - _self_

data:
  _target_: discrete_diffusion.data.datamodule.GraphDataModule

  datasets:
    train:
      _target_: discrete_diffusion.data.graph_dataset.GeneratedGraphDataset

    val:
      _target_: discrete_diffusion.data.graph_dataset.GeneratedGraphDataset

    test:
      _target_: discrete_diffusion.data.graph_dataset.GeneratedGraphDataset

  gpus: ${train.trainer.gpus}

  num_workers:
    train: 8
    val: 4
    test: 4

  batch_size:
    train: 16
    val: 16
    test: 16

  val_percentage: 0.1


module:
  _target_: discrete_diffusion.pl_modules.pl_module.DiffusionPLModule

  model:
    _target_: discrete_diffusion.modules.diffusion.Diffusion
    diffusion_speed: 0.01
    timesteps: 100
    num_nodes_samples: [4, 5]
    denoise_fn:
      _target_: discrete_diffusion.modules.link_predictor.LinkPredictor
      feature_dim: ???
      time_dim: 64
      node_embedder:
        _target_: discrete_diffusion.modules.node_embedder.NodeEmbedder
        feature_dim: ???
        num_mlp_layers: 2
        embedding_dim: 64
        hidden_dim: 64
        num_convs: 2
        dropout_rate: 0.
        do_preprocess: false
        use_batch_norm: true
        jump_mode: cat

  optimizer:
    #  Adam-oriented deep learning
    _target_: torch.optim.Adam
    #  These are all default parameters for the Adam optimizer
    lr: 0.001
    betas: [ 0.9, 0.999 ]
    eps: 1e-08
    weight_decay: 0

#  lr_scheduler:
#    _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts
#    T_0: 10
#    T_mult: 2
#    eta_min: 0 # min value for the lr
#    last_epoch: -1
#    verbose: False

# ROBA BRUTTA Added by Irene to make the code compatible with Song one
model:
  activation: "swish"
  scale_by_sigma: False
  ema_rate: 0.9999
  normalization: 'GroupNorm'
  nonlinearity: 'swish'
  nf: 32 #128 #
  ch_mult: [1, 1, 1, 1]
  num_res_blocks: 2
  # model.attn_resolutions = (2048,)
  resamp_with_conv: True
  conditional: True
  sigma_min: 0.01
  sigma_max: 50
  num_scales: 1000
  beta_min: 0.1
  beta_max: 20.
  dropout: 0.1
  embedding_type: 'fourier'
  centered: False
  num_channels: 1
