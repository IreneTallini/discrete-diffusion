defaults:
  - graph_generator: random_tree
  - _self_

data:
  _target_: discrete_diffusion.data.datamodule.GraphDataModule

  dataset_name: ENZYMES
  data_dir: ${oc.env:PROJECT_ROOT}/data/${nn.data.dataset_name}

  feature_params:
    features_to_consider:
      - degree
      - tags
    #      - num_cycles

    max_considered_cycle_len: 4

  datasets:
    train:
      _target_: discrete_diffusion.data.graph_dataset.GeneratedGraphDataset

    val:
      _target_: discrete_diffusion.data.graph_dataset.GeneratedGraphDataset

    test:
      _target_: discrete_diffusion.data.graph_dataset.GeneratedGraphDataset



  gpus: ${train.trainer.gpus}

  num_workers:
    train: 8
    val: 4
    test: 4

  batch_size:
    train: 16
    val: 1
    test: 1

  val_percentage: 0.1


module:
  _target_: discrete_diffusion.pl_modules.pl_module.DiffusionPLModule

  model:

    _target_: discrete_diffusion.modules.diffusion.Diffusion
    diffusion_speed: 0.01
    timesteps: 1 // ${nn.module.model.diffusion_speed}
    num_nodes_samples: [30]

    denoise_fn:
      _target_: discrete_diffusion.modules.link_predictor.LinkPredictor
      feature_dim: ???
      time_dim: 128

      node_embedder:
        _target_: discrete_diffusion.modules.node_embedder.NodeEmbedder
        feature_dim: ???
        num_mlp_layers: 2
        embedding_dim: ${nn.module.model.denoise_fn.time_dim}
        hidden_dim: ${nn.module.model.denoise_fn.time_dim}
        num_convs: 2
        dropout_rate: 0.1
        do_preprocess: false
        use_batch_norm: false
        jump_mode: none

  optimizer:
    _target_: torch.optim.Adam
    lr: 0.001

  lr_scheduler:
    _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts
    T_0: 10
    T_mult: 2
    eta_min: 0 # min value for the lr
    last_epoch: -1
    verbose: False
